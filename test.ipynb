{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NpzFile 'datasets/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz' with keys: metadata, imgs, latents_classes, latents_values"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Understand the structure of the dSprites dataset\n",
    "data = np.load('datasets/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz',\n",
    "                encoding='latin1', # These two\n",
    "                allow_pickle=True) # are for loading metadata\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_sizes = torch.Tensor(data[\"metadata\"][()][\"latents_sizes\"])\n",
    "# torch.index_select(latent_sizes, 0,torch.tensor([0,1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  3.,  6., 40., 32., 32.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.prod(latent_sizes.int())/torch.cumprod(latent_sizes.int(),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = torch.rand(10, len(latent_sizes))\n",
    "new_samples = (samples * (latent_sizes)).long().floor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([604108, 267977, 316720, 374397, 475746, 341568, 229797, 370521, 565354,\n",
       "        457936], dtype=torch.int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.tensor(np.dot(new_samples.numpy(), sample.numpy())).int()\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  2,  2, 29, 30, 12],\n",
       "        [ 0,  1,  0, 21, 22,  9],\n",
       "        [ 0,  1,  1, 29,  9, 16],\n",
       "        [ 0,  1,  3,  5, 19, 29],\n",
       "        [ 0,  1,  5, 24, 19,  2],\n",
       "        [ 0,  1,  2, 13, 18,  0],\n",
       "        [ 0,  0,  5, 24, 13,  5],\n",
       "        [ 0,  1,  3,  1, 26, 25],\n",
       "        [ 0,  2,  1, 32,  3, 10],\n",
       "        [ 0,  1,  5,  7,  6, 16]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  5,  2],\n",
       "        [ 2, 21,  2],\n",
       "        [ 1, 35, 16],\n",
       "        [ 2,  5, 15],\n",
       "        [ 0, 20, 26],\n",
       "        [ 1, 26, 11],\n",
       "        [ 2, 24, 23],\n",
       "        [ 0, 37,  1],\n",
       "        [ 1, 23, 26],\n",
       "        [ 0, 35, 24]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_samples[:,[1, 3 ,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_sizes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([138,  22,  84, 122, 104])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of random indices\n",
    "indices = np.random.randint(0, 200, 5)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.3728e+05, 2.4576e+05, 4.0960e+04, 1.0240e+03, 3.2000e+01,\n",
       "       1.0000e+00])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_sizes = np.array(data[\"metadata\"][()][\"latents_sizes\"])\n",
    "np.prod(factor_sizes)/ np.cumprod(factor_sizes) # number of images per factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can only specify one unknown dimension",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mimgs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msha[e]\n",
      "\u001b[0;31mValueError\u001b[0m: can only specify one unknown dimension"
     ]
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': 'April 2017',\n",
       " 'description': 'Disentanglement test Sprites dataset.Procedurally generated 2D shapes, from 6 disentangled latent factors.This dataset uses 6 latents, controlling the color, shape, scale, rotation and position of a sprite. All possible variations of the latents are present. Ordering along dimension 1 is fixed and can be mapped back to the exact latent values that generated that image.We made sure that the pixel outputs are different. No noise added.',\n",
       " 'version': 1,\n",
       " 'latents_names': ('color', 'shape', 'scale', 'orientation', 'posX', 'posY'),\n",
       " 'latents_possible_values': {'orientation': array([0.        , 0.16110732, 0.32221463, 0.48332195, 0.64442926,\n",
       "         0.80553658, 0.96664389, 1.12775121, 1.28885852, 1.44996584,\n",
       "         1.61107316, 1.77218047, 1.93328779, 2.0943951 , 2.25550242,\n",
       "         2.41660973, 2.57771705, 2.73882436, 2.89993168, 3.061039  ,\n",
       "         3.22214631, 3.38325363, 3.54436094, 3.70546826, 3.86657557,\n",
       "         4.02768289, 4.1887902 , 4.34989752, 4.51100484, 4.67211215,\n",
       "         4.83321947, 4.99432678, 5.1554341 , 5.31654141, 5.47764873,\n",
       "         5.63875604, 5.79986336, 5.96097068, 6.12207799, 6.28318531]),\n",
       "  'posX': array([0.        , 0.03225806, 0.06451613, 0.09677419, 0.12903226,\n",
       "         0.16129032, 0.19354839, 0.22580645, 0.25806452, 0.29032258,\n",
       "         0.32258065, 0.35483871, 0.38709677, 0.41935484, 0.4516129 ,\n",
       "         0.48387097, 0.51612903, 0.5483871 , 0.58064516, 0.61290323,\n",
       "         0.64516129, 0.67741935, 0.70967742, 0.74193548, 0.77419355,\n",
       "         0.80645161, 0.83870968, 0.87096774, 0.90322581, 0.93548387,\n",
       "         0.96774194, 1.        ]),\n",
       "  'posY': array([0.        , 0.03225806, 0.06451613, 0.09677419, 0.12903226,\n",
       "         0.16129032, 0.19354839, 0.22580645, 0.25806452, 0.29032258,\n",
       "         0.32258065, 0.35483871, 0.38709677, 0.41935484, 0.4516129 ,\n",
       "         0.48387097, 0.51612903, 0.5483871 , 0.58064516, 0.61290323,\n",
       "         0.64516129, 0.67741935, 0.70967742, 0.74193548, 0.77419355,\n",
       "         0.80645161, 0.83870968, 0.87096774, 0.90322581, 0.93548387,\n",
       "         0.96774194, 1.        ]),\n",
       "  'scale': array([0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       "  'shape': array([1., 2., 3.]),\n",
       "  'color': array([1.])},\n",
       " 'latents_sizes': array([ 1,  3,  6, 40, 32, 32]),\n",
       " 'author': 'lmatthey@google.com',\n",
       " 'title': 'dSprites dataset'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['metadata'][()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Training",
   "language": "python",
   "name": "training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
