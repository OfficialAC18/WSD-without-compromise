{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NpzFile 'datasets/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz' with keys: metadata, imgs, latents_classes, latents_values"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Understand the structure of the dSprites dataset\n",
    "data = np.load('datasets/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz',\n",
    "                encoding='latin1', # These two\n",
    "                allow_pickle=True) # are for loading metadata\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "737280"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imgs = torch.Tensor(data['imgs'])\n",
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.uint8\n",
      "torch.Size([737280, 4096]) None\n",
      "torch.Size([4096])\n"
     ]
    }
   ],
   "source": [
    "k = torch.from_numpy(data['imgs'])\n",
    "k = torch.reshape(k, (k.shape[0],-1))\n",
    "print(k.shape, print(k.dtype))\n",
    "\n",
    "\n",
    "out = torch.distributions.bernoulli.Bernoulli(probs = torch.clamp(k.float(), min = 1e-6, max = 1-1e-6))\n",
    "print(torch.sum(out.entropy(),dim=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([737280, 4096])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = torch.clamp(torch.randn(k.shape), min = 0.1, max = 0.9)\n",
    "logit = torch.log(logit/(1-logit))\n",
    "logit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3481, -1.1151, -2.1972,  ...,  2.1972, -2.1972, -2.1972],\n",
       "        [-2.1972,  0.6491,  2.1972,  ...,  0.9261, -2.1972,  2.1972],\n",
       "        [-2.1972, -2.1972, -2.1972,  ..., -2.1972,  2.1972,  2.1972],\n",
       "        ...,\n",
       "        [-2.1972, -2.1972,  1.1770,  ..., -2.1972,  1.7386, -0.6148],\n",
       "        [ 0.4552, -2.1972, -1.3803,  ...,  2.1972, -2.1972, -1.5469],\n",
       "        [-2.1972, -0.9131, -2.1972,  ..., -2.1972,  0.4492,  2.1972]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-69663.8438)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.sum(F.binary_cross_entropy_with_logits(logit, logit**3, reduction='none'),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_sizes = torch.Tensor(data[\"metadata\"][()][\"latents_sizes\"])\n",
    "# torch.index_select(latent_sizes, 0,torch.tensor([0,1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  3.,  6., 40., 32., 32.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.3728e+05, 2.4576e+05, 4.0960e+04, 1.0240e+03, 3.2000e+01, 1.0000e+00])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_bases = torch.prod(latent_sizes.int())/torch.cumprod(latent_sizes.int(),axis=0)\n",
    "factor_bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = torch.rand(10, len(latent_sizes))\n",
    "new_samples = (samples * (latent_sizes)).int().floor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  3.,  6., 40., 32., 32.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0, 21, 17, 22],\n",
       "        [ 0,  0,  2, 13,  8, 22],\n",
       "        [ 0,  2,  0,  5, 21,  6],\n",
       "        [ 0,  1,  0,  8, 31, 16],\n",
       "        [ 0,  0,  0, 26,  6, 18],\n",
       "        [ 0,  0,  0,  9, 24,  3],\n",
       "        [ 0,  0,  2, 17, 18,  9],\n",
       "        [ 0,  2,  0, 30, 30,  6],\n",
       "        [ 0,  2,  3, 27, 27, 17],\n",
       "        [ 0,  1,  2, 24,  7,  9]], dtype=torch.int32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([604108, 267977, 316720, 374397, 475746, 341568, 229797, 370521, 565354,\n",
       "        457936], dtype=torch.int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.tensor(np.dot(new_samples.numpy(), sample.numpy())).int()\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  0, 21, 17, 22],\n",
      "        [ 0,  0,  2, 13,  8, 22],\n",
      "        [ 0,  2,  0,  5, 21,  6],\n",
      "        [ 0,  1,  0,  8, 31, 16],\n",
      "        [ 0,  0,  0, 26,  6, 18],\n",
      "        [ 0,  0,  0,  9, 24,  3],\n",
      "        [ 0,  0,  2, 17, 18,  9],\n",
      "        [ 0,  2,  0, 30, 30,  6],\n",
      "        [ 0,  2,  3, 27, 27, 17],\n",
      "        [ 0,  1,  2, 24,  7,  9]], dtype=torch.int32)\n",
      "tensor([737280, 245760,  40960,   1024,     32,      1], dtype=torch.int32)\n",
      "tensor([ 22070,  95510, 497318, 254960,  26834,   9987,  99913, 523206, 642929,\n",
      "        352489], dtype=torch.int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 6]), torch.Size([6]), torch.Size([10, 1, 128, 64]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(new_samples)\n",
    "print(factor_bases.int())\n",
    "idxs = torch.matmul(new_samples, factor_bases.int())\n",
    "print(idxs)\n",
    "new_samples.shape, factor_bases.shape, torch.concatenate((imgs[idxs],imgs[idxs]),axis=1).unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(imgs[idxs][1] == imgs[95510])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  4,  7, 28, 11],\n",
       "        [ 0,  2,  0, 29,  8, 21],\n",
       "        [ 0,  2,  3,  5, 16, 19],\n",
       "        [ 0,  1,  0,  5, 29, 19],\n",
       "        [ 0,  0,  2, 38, 15, 17],\n",
       "        [ 0,  0,  1, 29, 22, 21],\n",
       "        [ 0,  2,  3, 19, 19, 26],\n",
       "        [ 0,  1,  5, 17, 10, 11],\n",
       "        [ 0,  0,  1, 35, 25, 15],\n",
       "        [ 0,  1,  1, 36, 30, 17]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  5,  2],\n",
       "        [ 2, 21,  2],\n",
       "        [ 1, 35, 16],\n",
       "        [ 2,  5, 15],\n",
       "        [ 0, 20, 26],\n",
       "        [ 1, 26, 11],\n",
       "        [ 2, 24, 23],\n",
       "        [ 0, 37,  1],\n",
       "        [ 1, 23, 26],\n",
       "        [ 0, 35, 24]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_samples[:,[1, 3 ,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_sizes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([138,  22,  84, 122, 104])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of random indices\n",
    "indices = np.random.randint(0, 200, 5)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.3728e+05, 2.4576e+05, 4.0960e+04, 1.0240e+03, 3.2000e+01,\n",
       "       1.0000e+00])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_sizes = np.array(data[\"metadata\"][()][\"latents_sizes\"])\n",
    "np.prod(factor_sizes)/ np.cumprod(factor_sizes) # number of images per factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can only specify one unknown dimension",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mimgs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msha[e]\n",
      "\u001b[0;31mValueError\u001b[0m: can only specify one unknown dimension"
     ]
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': 'April 2017',\n",
       " 'description': 'Disentanglement test Sprites dataset.Procedurally generated 2D shapes, from 6 disentangled latent factors.This dataset uses 6 latents, controlling the color, shape, scale, rotation and position of a sprite. All possible variations of the latents are present. Ordering along dimension 1 is fixed and can be mapped back to the exact latent values that generated that image.We made sure that the pixel outputs are different. No noise added.',\n",
       " 'version': 1,\n",
       " 'latents_names': ('color', 'shape', 'scale', 'orientation', 'posX', 'posY'),\n",
       " 'latents_possible_values': {'orientation': array([0.        , 0.16110732, 0.32221463, 0.48332195, 0.64442926,\n",
       "         0.80553658, 0.96664389, 1.12775121, 1.28885852, 1.44996584,\n",
       "         1.61107316, 1.77218047, 1.93328779, 2.0943951 , 2.25550242,\n",
       "         2.41660973, 2.57771705, 2.73882436, 2.89993168, 3.061039  ,\n",
       "         3.22214631, 3.38325363, 3.54436094, 3.70546826, 3.86657557,\n",
       "         4.02768289, 4.1887902 , 4.34989752, 4.51100484, 4.67211215,\n",
       "         4.83321947, 4.99432678, 5.1554341 , 5.31654141, 5.47764873,\n",
       "         5.63875604, 5.79986336, 5.96097068, 6.12207799, 6.28318531]),\n",
       "  'posX': array([0.        , 0.03225806, 0.06451613, 0.09677419, 0.12903226,\n",
       "         0.16129032, 0.19354839, 0.22580645, 0.25806452, 0.29032258,\n",
       "         0.32258065, 0.35483871, 0.38709677, 0.41935484, 0.4516129 ,\n",
       "         0.48387097, 0.51612903, 0.5483871 , 0.58064516, 0.61290323,\n",
       "         0.64516129, 0.67741935, 0.70967742, 0.74193548, 0.77419355,\n",
       "         0.80645161, 0.83870968, 0.87096774, 0.90322581, 0.93548387,\n",
       "         0.96774194, 1.        ]),\n",
       "  'posY': array([0.        , 0.03225806, 0.06451613, 0.09677419, 0.12903226,\n",
       "         0.16129032, 0.19354839, 0.22580645, 0.25806452, 0.29032258,\n",
       "         0.32258065, 0.35483871, 0.38709677, 0.41935484, 0.4516129 ,\n",
       "         0.48387097, 0.51612903, 0.5483871 , 0.58064516, 0.61290323,\n",
       "         0.64516129, 0.67741935, 0.70967742, 0.74193548, 0.77419355,\n",
       "         0.80645161, 0.83870968, 0.87096774, 0.90322581, 0.93548387,\n",
       "         0.96774194, 1.        ]),\n",
       "  'scale': array([0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       "  'shape': array([1., 2., 3.]),\n",
       "  'color': array([1.])},\n",
       " 'latents_sizes': array([ 1,  3,  6, 40, 32, 32]),\n",
       " 'author': 'lmatthey@google.com',\n",
       " 'title': 'dSprites dataset'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['metadata'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0,10,(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create A Train-Val set\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "imgs = os.listdir('datasets/playing_cards_minimal/train')\n",
    "X_train, X_val = train_test_split(imgs, test_size=0.2, random_state=42)\n",
    "\n",
    "#Move the val images to the val folder\n",
    "import shutil\n",
    "for img in X_val:\n",
    "    shutil.move('datasets/playing_cards_minimal/train/'+img, 'datasets/playing_cards_minimal/val/'+img)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2964"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WSD-WO-COMP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
